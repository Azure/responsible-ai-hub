"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"dashboardSidebar":[{"type":"link","label":"Responsible AI Dashboard","href":"/responsible-ai-hub/docs/rai-dashboard-ms-learn","docId":"responsible-ai-dashboard-mslearn/rai-ms-learn","unlisted":false}],"contentSafetySidebar":[{"type":"link","label":"Overview","href":"/responsible-ai-hub/docs/content-safety-overview","docId":"azure-content-safety/cs-intro","unlisted":false},{"type":"link","label":"Lab 1 - GitHub Codespaces","href":"/responsible-ai-hub/docs/content-safety-codespaces","docId":"azure-content-safety/lab1-launch-github-codespace/cs-codespaces-lab1\'","unlisted":false},{"type":"link","label":"Lab 2 -  Create Content Safety instance","href":"/responsible-ai-hub/docs/content-safety-resource","docId":"azure-content-safety/lab2-create-content-safety/content-safety-lab2\'","unlisted":false},{"type":"link","label":"Lab 3 -  Analyze Text","href":"/responsible-ai-hub/docs/content-safety-analyze-text","docId":"azure-content-safety/lab3-analyze-text/cs-analyze-text-lab4\'","unlisted":false},{"type":"link","label":"Lab 5 - Analyze Image","href":"/responsible-ai-hub/docs/content-safety-analyze-image","docId":"azure-content-safety/lab4-analyze-image/cs-analyze-image-lab4\'","unlisted":false},{"type":"category","label":"Lab 5 - OpenAI playground","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Lab# 5: Azure OpenAI Playground","href":"/responsible-ai-hub/docs/azure-openai-playground","docId":"azure-content-safety/lab5-openai-playground/azure-openai-playground-lab5\'","unlisted":false}],"href":"/responsible-ai-hub/docs/openai-playground"}],"promptFlowSidebar":[{"type":"link","label":"Prompt Flow Overview","href":"/responsible-ai-hub/docs/prompt-flow-overview","docId":"azure-prompt-flow/pf-intro","unlisted":false},{"type":"category","label":"Prompt Flow On Azure","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Lab 1 | Create Azure Resources","href":"/responsible-ai-hub/docs/build-workshop-enviroment","docId":"azure-prompt-flow/portal/lab1-create-azure-resources/prompt-flow-lab1","unlisted":false},{"type":"link","label":"Lab 2 | Bring your data","href":"/responsible-ai-hub/docs/bring-your-data","docId":"azure-prompt-flow/portal/lab2-bring-your-data/pf-bring-your-data-lab2\'","unlisted":false},{"type":"category","label":"Lab 3 | Add Flow Connections","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Lab# 3: Add flow connections","href":"/responsible-ai-hub/docs/add-flow-connections","docId":"azure-prompt-flow/portal/lab3-add-flow-connections/pf-add-flow-connection-lab3\'","unlisted":false}]},{"type":"category","label":"Lab 4 | Create Chat Template","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Lab# 4: Create chatbot template","href":"/responsible-ai-hub/docs/create-chatbot-template","docId":"azure-prompt-flow/portal/lab4-chatbot-template/pf-create-chatbot-template-lab4\'","unlisted":false}]},{"type":"link","label":"Lab 5 | Chatbot with your data","href":"/responsible-ai-hub/docs/chatbot-with-your-data","docId":"azure-prompt-flow/portal/lab5-chatbot-with-your-data/pf-chatbot-with-your-data-lab5\'","unlisted":false},{"type":"category","label":"Lab 6 | Evaluate Chatbot","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Lab# 6: Evaluate chatbot","href":"/responsible-ai-hub/docs/evaluate-chatbot","docId":"azure-prompt-flow/portal/lab6-evaluate chatbot/pf-evaluate-chatbot-lab6\'","unlisted":false}]}]}]},"docs":{"azure-content-safety/cs-intro":{"id":"azure-content-safety/cs-intro","title":"Overview","description":"As we build applications that engage with people, it\u2019s vital that the content that is displayed to the end-user is not harmful or offensive.  In this workshop you will learn how to use the prebuilt AI service, Azure Safety Content, in your applications to ensure that the texts or images that are sent to the user or the user enters do not contain data that has violence, self-harm, hate or sexual information.  In addition, based on the demographic of the end-users that interact with the application, developers can control what content is acceptable based on the sensitivity level of the inappropriate content. The services support multiple languages and multiple industries such as gaming, e-commerce, social media, education, etc.","sidebar":"contentSafetySidebar"},"azure-content-safety/lab1-launch-github-codespace/cs-codespaces-lab1\'":{"id":"azure-content-safety/lab1-launch-github-codespace/cs-codespaces-lab1\'","title":"Lab# 1: Launch GitHub codespaces project","description":"To expedite running the workspace and having a consistent project environment, we\u2019ll be using GitHub codespaces.","sidebar":"contentSafetySidebar"},"azure-content-safety/lab2-create-content-safety/content-safety-lab2\'":{"id":"azure-content-safety/lab2-create-content-safety/content-safety-lab2\'","title":"Lab# 2: Create Azure Content Safety","description":"To complete this lesson, you would need a Azure OpenAI and Azure Content Safety. If you don\'t have OpenAI in your subscription, you\'ll only be creating an Azure Content Safety resource.","sidebar":"contentSafetySidebar"},"azure-content-safety/lab3-analyze-text/cs-analyze-text-lab4\'":{"id":"azure-content-safety/lab3-analyze-text/cs-analyze-text-lab4\'","title":"Lab# 4: Analyze Text","description":"When dealing with text, it is either user or application generated. With Generative AI, we need to be mindful that the text to be examined is either user input prompts or AI generated responses. For example, one of the challenges of using social media or Chat applications to a demographic of high school students is that it introduces system vulnerabilities for users to enter text that have profanity, bullying, harassment, derogatory implications etc.","sidebar":"contentSafetySidebar"},"azure-content-safety/lab4-analyze-image/cs-analyze-image-lab4\'":{"id":"azure-content-safety/lab4-analyze-image/cs-analyze-image-lab4\'","title":"Lab# 4: Analyze Image","description":"There are tons of applications and social medial sites that enable users to upload images. This opens a flood gate of opportunities for users to upload sexual derogative content, violence, or harmful content. Similar to text, it\u2019s not realistic to rely on users to flag inappropriate content or the staff to manually see the content when it\u2019s uploaded.  Even with manual monitors, images are subjected to each individual evaluator to determine if it is risky.","sidebar":"contentSafetySidebar"},"azure-content-safety/lab5-openai-playground/azure-openai-playground-lab5\'":{"id":"azure-content-safety/lab5-openai-playground/azure-openai-playground-lab5\'","title":"Lab# 5: Azure OpenAI Playground","description":"If you do have Azure OpenAI in your Azure subscription, then you can use this Chat playground. You need an Azure subscription with Azure OpenAI to access the playground. You will need a modern browser - to access both the tutorial and playground.","sidebar":"contentSafetySidebar"},"azure-content-safety/lab5-openai-playground/openai-playground-lab5\'":{"id":"azure-content-safety/lab5-openai-playground/openai-playground-lab5\'","title":"Lab# 5: OpenAI Playground","description":"If you do not have Azure OpenAI in your Azure subscription, then you can use this Chat playground.","sidebar":"contentSafetySidebar"},"azure-prompt-flow/pf-intro":{"id":"azure-prompt-flow/pf-intro","title":"Prompt Flow Overview","description":"Prompt engineering is a tedious process that involves a lot tasks and components.  Developments have next determine what the input or prompts are going to be and what the actions we want in return.  In order to achieve, there are a lot of parts.  For instance, the prompts are responses need to be tokenize.  Next, depending on that the action that will be the output, we need to identify where that information is coming from.  Is the information coming from an API, or an LLM model?  When data is returned, does it need preprocessing?  How is the best response identify?","sidebar":"promptFlowSidebar"},"azure-prompt-flow/portal/lab1-create-azure-resources/prompt-flow-lab1":{"id":"azure-prompt-flow/portal/lab1-create-azure-resources/prompt-flow-lab1","title":"Lab# 1: Build Workshop Environment","description":"As you work on creating Flows, it may have dependencies, services or external resources that you would need to connect to; such as OpenAI, Content Safety AI or your custom LLM models.  It enables users to add and manage connection to these resources as well as a their connection secrets (e.g. name, api key, api_endpoint, or type).","sidebar":"promptFlowSidebar"},"azure-prompt-flow/portal/lab2-bring-your-data/pf-bring-your-data-lab2\'":{"id":"azure-prompt-flow/portal/lab2-bring-your-data/pf-bring-your-data-lab2\'","title":"Lab# 2: Bring your own data","description":"Open AI and most LLM models are training from various publicly available data.  However, there are instances where we need to use our own data and narrow the actions and data search of our LLM prompts to focus only on the scope of our data or expand the data from LLM model to include our data as well.  To use your own data in a LLM, you need to convert you data into numeric values.  Each word mapping to a specific number (token).  Then you train a model to find similarities, collations, or word association, the model creates vector indexes to the word associations.   The good thing is the Prompt Flow service provide an easy-to-use process your to upload dataset and it generates model and the Vector indexes.","sidebar":"promptFlowSidebar"},"azure-prompt-flow/portal/lab3-add-flow-connections/pf-add-flow-connection-lab3\'":{"id":"azure-prompt-flow/portal/lab3-add-flow-connections/pf-add-flow-connection-lab3\'","title":"Lab# 3: Add flow connections","description":"To use Prompt Flow, you need to enable the feature in Azure ML studio.  To enable the feature, complete the following steps:","sidebar":"promptFlowSidebar"},"azure-prompt-flow/portal/lab4-chatbot-template/pf-create-chatbot-template-lab4\'":{"id":"azure-prompt-flow/portal/lab4-chatbot-template/pf-create-chatbot-template-lab4\'","title":"Lab# 4: Create chatbot template","description":"We will learn how to create a basic chat agent that interacts with prompts power by an OpenAI model.","sidebar":"promptFlowSidebar"},"azure-prompt-flow/portal/lab5-chatbot-with-your-data/pf-chatbot-with-your-data-lab5\'":{"id":"azure-prompt-flow/portal/lab5-chatbot-with-your-data/pf-chatbot-with-your-data-lab5\'","title":"Lab# 5: Chatbot with your data","description":"In the precise exercise you create a vector index and train to search for your vector embeddings.  In this exercise, you\u2019ll be expanding the Chat pipeline logic to take the user question and convert to numeric embeddings.  Then we\u2019ll use the numeric embedding to search the numeric vector.  Next, we\u2019ll use the prompt to set rules with restrictions and how to display the data to the user.","sidebar":"promptFlowSidebar"},"azure-prompt-flow/portal/lab6-evaluate chatbot/pf-evaluate-chatbot-lab6\'":{"id":"azure-prompt-flow/portal/lab6-evaluate chatbot/pf-evaluate-chatbot-lab6\'","title":"Lab# 6: Evaluate chatbot","description":"You can unit test your Flow.  However, Prompt flow provides a gallery of sample evaluation flows your can use to test you Flow in bulk.  For example, classification accuracy, QnA Groundedness, QnA Relevant, QnA Similarity, QnA F1 Score etc.  This enables you to test how well your LLM is performing.  In addition, you have the ability to examine which of your variant prompts are performing better.   In this example, we\u2019ll use the QnA RAG Evaluation template to test our flow.","sidebar":"promptFlowSidebar"},"badges":{"id":"badges","title":"Claim your badge","description":"Congratulations on completing the Azure Responsible AI workshop!"},"Cleanup":{"id":"Cleanup","title":"Cleanup","description":"Be sure to shutdown the compute instance at the end of this workshop so you do not run out of credits."},"References":{"id":"References","title":"Tutorials","description":"To get a deeper understanding of all the Responsible AI dashboard features and components, refer to the following tutorials series:"},"responsible-ai-dashboard-mslearn/rai-ms-learn":{"id":"responsible-ai-dashboard-mslearn/rai-ms-learn","title":"Responsible AI Dashboard","description":"In this session, you\'ll complete a hands-on lab that will teach you how to debug an AI model using the Responsible AI Dashboard in Azure Machine Learning Studio, to ensure that  it performs responsibly and is less harmful.","sidebar":"dashboardSidebar"},"Survey":{"id":"Survey","title":"Survey","description":"Congratulations on completing the workshop! We hope you enjoyed the experience and learned a lot about the Responsible AI dashboard. We would love to hear your feedback on the training. Please take a few minutes to complete the survey below."}}}')}}]);